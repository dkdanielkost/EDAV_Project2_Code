---
title: "EDAV-Project2"
author: "Team"
date: "February 18, 2016"
output: html_document
---
#Introduction 
For this report we will be diving into the global issue of Flood Events. The intial goal of the paper will be to investigate the datasets to better understand. The dataset being investigated involves geographical, spatial, and time parameters that creates an extremely large amount of information to be explored. We will work to break down this large dataset into something smaller and begin to focus on specific events within the flood dataset.

```{r, message=F, warning=F, echo = F}
library(dplyr)
library(ggplot2)
library(maps)
library(grid)
library(gridExtra)
library(knitr)
library(googleVis)
library(gdata)
library(plyr)
library(ncdf.tools)
library(chron)
setwd("/Users/bobminnich/Documents/Columbia/Courses/DataVisualization/Homework2/EDAV_Project2_Code")
```

###Global Flood Events: From  Januaray 1st 1985 to December 23, 2015
EXPLANATION NEEDED
```{r, message=F, warning=F, echo = FALSE, fig.align='center'}
df = readRDS("GlobalFloodsRecord_modified.rds")

require(ggplot2)
world_map <- map_data("world")


df1 = df[,c("Centroid X","Centroid Y")]
colnames(df1)[which(names(df1) == "Centroid X")] <- "CentroidX"
colnames(df1)[which(names(df1) == "Centroid Y")] <- "CentroidY"

df1$CentroidX=as.numeric(levels(df1$CentroidX))[df1$CentroidX]
df1$CentroidY=as.numeric(levels(df1$CentroidY))[df1$CentroidY]
df1 = df1[complete.cases(df1$CentroidX),]

col.nacheck3 = data.frame(colSums(is.na(df1)))

p <- ggplot() + coord_fixed() + xlab("") + ylab("")
base_world_messy <- p + geom_polygon(data=world_map, aes(x=long, y=lat, group=group), 
                                     colour="light green", fill="light green")

#base_world_messy
cleanup <- 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_rect(fill = 'white', colour = 'white'), 
        axis.line = element_line(colour = "white"), legend.position="none",
        axis.ticks=element_blank(), axis.text.x=element_blank(),
        axis.text.y=element_blank())

base_world <- base_world_messy + cleanup

#base_world + ggtitle("World Map")
map_data = base_world +geom_point(data=df1, aes(x=CentroidX, y=CentroidY), colour="Red",fill="Pink",pch=21, size=2, alpha=I(0.5)) + ggtitle("World Map of Global Flood Events from 1985 to 2003")

map_data

```

```{r, message=F, warning=F, echo = FALSE, fig.align='center'}
setwd("/Users/bobminnich/Documents/Columbia/Courses/DataVisualization/Homework2/EDAV_Project2_Code")

df = readRDS("GlobalFloodsRecord.rds")
df$Displaced = as.numeric(df$Displaced)
df$Dead = as.numeric(df$Dead)
df$Country = as.factor(df$Country)
df$Centroid.X = as.numeric(as.character(df$Centroid.X))
df$Centroid.Y = as.numeric(as.character(df$Centroid.Y))
df$Magnitude..M... = as.numeric(as.character(df$Magnitude..M...))
df$Affected.sq.km = as.numeric(as.character(df$Affected.sq.km))
df$Duration.in.Days = as.numeric(as.character(df$Duration.in.Days))

ele = readRDS("elevation.RDS")
df = cbind(df,ele)


#setwd("/Users/bobminnich/Documents/Columbia/Courses/DataVisualization/Homework2/EDAV_Project2_Code/Project2")


startend = read.csv("Start_End.csv", header = TRUE)
df$Began = as.Date(startend$Start, "%d-%b-%y") 
df$Ended = as.Date(startend$End, "%d-%b-%y") 

month_clean <- data.frame(do.call('rbind', strsplit(as.character(df$Began),"-")))
colnames(month_clean) = c("Year", "Month", "Day")

df$Year = as.factor(month_clean$Year)
df$Month = as.factor(month_clean$Month)
df$Day = as.factor(month_clean$Day)

  #Split between northen and southern
southern = df$latitude < 0
df$hem[southern] = "S"
df$hem[!southern] = "N"


```


In order to understand the map data we begin to break it down by different categories and look at countries with the largest totals in each.

```{r, message=F, warning=F, echo = FALSE, fig.align='center'}
top = 10
displaced_count = df[,c("Country", "Displaced", "hem")]%>%
  group_by(Country, hem) %>%
  summarize(Displaced = sum(Displaced))

displaced_order = order(displaced_count$Displaced,decreasing  = TRUE)
top10_dis = displaced_count[displaced_order[1:top],]


death_toll = df[,c("Country", "Dead", "hem")]%>%
  group_by(Country, hem) %>%
  summarize(Dead = sum(Dead))

death_order = order(death_toll$Dead,decreasing  = TRUE)
top10_death = death_toll[death_order[1:top],]


flood_count = df[,c("Country", "Register..", "hem")]%>%
  group_by(Country, hem) %>%
  summarize(count = n())

flood_count_order = order(flood_count$count,decreasing  = TRUE)
top10_flood = flood_count[flood_count_order[1:top],]

```



```{r, message=F, warning=F, echo = FALSE, fig.align='center'}

c = ggplot(top10_dis, aes(x = factor(Country), y = Displaced)) +
  geom_bar(aes(group=hem, colour=hem, fill=hem),stat = "identity")+
  #coord_flip()+
    ggtitle("Number of Displaced")+
  ylab("Number of Displaced")+
  xlab("Country")+ theme(legend.position="none")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(axis.title.y = element_blank())+ theme(axis.title.x = element_blank())
b = ggplot(top10_death, aes(x = factor(Country), y = Dead)) +
  geom_bar(aes(group=hem, colour=hem, fill=hem),stat = "identity")+
  #coord_flip()+
  ggtitle("Number of Deaths")+
  xlab("Country")+ theme(legend.position="none")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(axis.title.y = element_blank())+ theme(axis.title.x = element_blank())
a  = ggplot(top10_flood, aes(x = factor(Country), y = count)) +
  geom_bar(stat = "identity",aes(group=hem, colour=hem, fill=hem))+
  #coord_flip()+
  ggtitle("Number of Flood Events")+
  ylab("Numer of Total Flood Events")+
   theme(legend.position="none")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(axis.title.y = element_blank())  + theme(axis.title.x = element_blank())


```

```{r, message=F, warning=F, echo = FALSE, fig.align='center'}
#dev.off()
#dev.new()
  MainTitle = paste("Top", top, "Countries for:")
  grid.newpage()
  pushViewport(viewport(layout = grid.layout(3, 3, heights = unit(c(0.1, 1,0.1), "null"))))
  grid.text(MainTitle, vp = viewport(layout.pos.row = 1, layout.pos.col = 2, just = "center"))
  print(a, vp = viewport(layout.pos.row = 2, layout.pos.col = 1),newpage=FALSE)
  print(b, vp = viewport(layout.pos.row = 2, layout.pos.col = 2),newpage=FALSE)
  print(c, vp = viewport(layout.pos.row = 2, layout.pos.col = 3),newpage=FALSE)
  
  MainTitle = paste("Red is for Northern Hemisphere, Blue is for Southern Hemisphere")

    grid.text(MainTitle, vp = viewport(layout.pos.row = 3, layout.pos.col = 1:3, just = "center"))


```

We can see that there are some insights within some of these plots. We can see that there are several countries that appear in all three plots. These are Brazil,China,Indea,Indonesia,Phillippines,USA and Vienam. Seeing some of the more devloped countries such as the USA seems surprising here because of how many flood events actually occur. There could be a difference in reporting here as well, such as the USA has been recording these events longer and therefore has a higher number of events.


Another interesting finding is that Iran, Pakistan and Afghanistan appear in the highest number of deaths but not in the highest number of displaced. Looking deeper into these categoies we find that they just mostlikely missed the top 10.

* Iran we can see that there were 9,107 deaths which also accompanied 10,364 displaced.

* Pakistan we can see that there were 9,346 deaths which also accompanied 14,611 displaced.

* Afghanistan we can see that there were 9,150 deaths which also accompanied 10,931 displaced.

So we can see a positive correlation occuring between the number of Flood Events, Deaths and Displaced.


```{r, message=F, warning=F, echo = FALSE, fig.align='center'}
#The following is to use the google API to determine elevations
#library(rgbif)
#bobkey = "AIzaSyD-8g3l-VX8TyUUI2wHUyLGBrWYQaBj-vs"
#ele = data.frame(t(rbind(df$Centroid.X, df$Centroid.Y)))
#colnames(ele) = c("decimalLongitude","decimalLatitude")
#test = elevation(ele, ele$decimalLatitude, ele$decimalLongitude, key = bobkey)
#newdf = cbind(df,test)

```




##Word Cloud

Word clouds were used to try and analyze the differences between the Northern Hemisphere (postive Latitude) and the Sourthern Hemisphere (negative Latitude). We wanted to investigate the column labeled "Notes and Comments", which included many news articles after cleaning the text the following word clouds were produced.


<div style="text-align: center;">

  <IMG SRC="WorldCloud_Entire.png" ALT="image",  width= "500">
  <span style="float:left;width: 50%;">
  <IMG SRC="WordCloud_Northern.png" float = "right" ALT="image">
  </span>
  
  <span style="float:right;width: 50%;">
  <IMG SRC="WordCloud_Southern.png" float = "left" ALT="image">
  </span>
  
</div>

What we can see from these plots is an interesting split between the Northern and Southern hemispheres. "People", was largely contributed by the Southern Hemisphere and "Flooding" was more attributed to the Northern.


We then continued looking into the differences between northern and southern hemispheres looking at density plots of varios attributes of the flood events.

```{r, message=F, warning=F, echo = FALSE, fig.align='center'}

#Over entire time
a = ggplot(df, aes(x = (Began))) +
    geom_density(aes( colour="#F8766D", fill="#F8766D"),alpha=0.3) +
  #ggtitle("Top 10 Cou+ntries: Death Toll")+
    labs(y = "Density") + theme(legend.position="none")+
      theme(axis.title.x = element_blank()) +ggtitle("Total Time Period")


b = ggplot(df, aes(x = (Began))) +
    geom_density(aes(group=hem, colour=hem, fill=hem),alpha=0.3) +
  #ggtitle("Density Plot: Month - Red = Northern, Blue = Southern")+ 
    theme(axis.title.x = element_blank()) + theme(legend.position="none")+
  ylab("Density")

#Over entire time by month

df$Month = as.numeric(month_clean$Month)

c = ggplot(df, aes(x = (Month))) +
    geom_density(aes( colour="#F8766D", fill="#F8766D"),alpha=0.3) +
  #ggtitle("Top 10 Cou+ntries: Death Toll")+
  theme(legend.position="none")+ 
    theme(axis.title.y = element_blank())+      
  theme(axis.title.x = element_blank()) + ggtitle("Grouped by Month")



#Over entire time by month by hemisphere

d = ggplot(df, aes(x = (Month))) +
    geom_density(aes(colour=hem, fill=hem),alpha=0.3) +
  theme(axis.title.y = element_blank(),axis.title.x = element_blank())+
  theme(legend.title=element_blank())

e = ggplot(df, aes(x = (Began))) +
    geom_density(aes(group=Severity.., colour=Severity.., fill=Severity..),alpha=0.3) +
  #ggtitle("Top 10 Cou+ntries: Death Toll")+ 
  theme(legend.position="none")+
  labs(y = "Density")+
  xlab("Total Time Period")

f = ggplot(df, aes(x = (Month))) +
    geom_density(aes(group=Severity.., colour=Severity.., fill=Severity..),alpha=0.3) +
    #ggtitle("Top 10 Cou+ntries: Death Toll") + 
    theme(axis.title.y = element_blank())+    
    theme(legend.title=element_blank()) + 
    xlab("Grouped by Month")
```

```{r, message=F, warning=F, echo = FALSE, fig.align='center', fig.width=8}
  grid.newpage()
  pushViewport(viewport(layout = grid.layout(6, 2, heights = unit(c(0.2,1,0.2,1,0.2,1), "null"))))
  
  #grid.text(MainTitle, vp = viewport(layout.pos.row = 1, layout.pos.col = 1:2))
  
  MainTitle = "Density Plots of Flood Events"
  grid.text(MainTitle, vp = viewport(layout.pos.row = 1, layout.pos.col = 1:2))
  print(a, vp = viewport(layout.pos.row = 2, layout.pos.col = 1),newpage=FALSE)
  print(c, vp = viewport(layout.pos.row = 2, layout.pos.col = 2),newpage=FALSE)
  MainTitle = "Differences between hemispheres"
  grid.text(MainTitle, vp = viewport(layout.pos.row = 3, layout.pos.col = 1:2))
  print(b, vp = viewport(layout.pos.row = 4, layout.pos.col = 1),newpage=FALSE)
  print(d, vp = viewport(layout.pos.row = 4, layout.pos.col = 2),newpage=FALSE)
  MainTitle = "Severity"
  grid.text(MainTitle, vp = viewport(layout.pos.row = 5, layout.pos.col = 1:2))
  print(e, vp = viewport(layout.pos.row = 6, layout.pos.col = 1),newpage=FALSE)
  print(f, vp = viewport(layout.pos.row = 6, layout.pos.col = 2),newpage=FALSE)

```

These density plots show us that the total number of flood events occured between the years of 2002 - 2003 by looking at the left column of plots "Total Time Period" Looking at  "Differences between Hemispheres" we can actually see this may be mostly contributed by the Southern Hemisphere Countries begining to record their Flood Events along with the countries in the Northern Hemisphere. We can see that from 2002 on the Southern Hemisphere makes up more of the recorded events.

From teh same column we can look at the Severity Plots for the Total Time Period. The Middle Severity of 1.5 does not start until 2005. This suggests that the rating for this category did not previously exist, judging by how much it is currently used.

We then began to look for correlations between elevation and different aspects of the flooding events. The general intution would be that the higher the elevation, the lower the number of flood events

As we look at the right side of the plots "Groupd by Month" we can further see some interesting characteristics. Looking at the upper right plot it would seem that for the world most of the flooding occurs in the 7th month, July. However as we break this down to Northern and Southern Hemispheres we can see that these seasons are opposite for each region. This makes sense because the different hemispheres experience opposite seasons.

Severity per month does not tell us much more additional information, the splits are very similar.


##Time Lapse
Here we have a Time Lapse of the busiest year in terms of flood events. We can see the events appear as black dots on the world map.

#Still need to load full GIF. Will load it once everyone has their code in.

<div style="text-align: center;"><IMG SRC="2003-OCT.gif" ALT="image", width="500"></div>

We can notice a large amount of cycling that happens in this year.

```{r, message=F, warning=F, echo = FALSE, fig.align='center'}
  

filtered = filter(df, elevation>0)


a = ggplot(filtered, aes(elevation)) +
    geom_density(aes(group=hem, colour=hem, fill=hem),alpha=0.3)+ 
  theme(legend.position="none")+
  ylab("Density")+
  xlab("Elevation ")

b = ggplot(filtered, aes(Duration.in.Days)) +
    geom_density(aes(group=hem, colour=hem, fill=hem),alpha=0.3)+
    xlim(0,100) +   theme(legend.title=element_blank()) + 
    xlab("Duration in Days")+
    theme(axis.title.y = element_blank())

c = ggplot(filtered, aes(x=elevation, y=Duration.in.Days)) +
    geom_point(aes(group=hem, colour=hem, fill=hem),alpha = .4) +    # Use hollow circles
   geom_smooth(method = "lm")+
  ylab("Duration in Days")+
  xlab("Elevation")

duration = df[which.max(df$Duration.in.Days),c("Country", "Duration.in.Days")]


test = filtered[-which.max(filtered$Duration.in.Days),]
duration2 = test[which.max(test$Duration.in.Days),c("Country", "Duration.in.Days")]

d = ggplot(test, aes(x=elevation, y=Duration.in.Days)) +
    geom_point(aes(group=hem, colour=hem, fill=hem),alpha = .25) +    # Use hollow circles
   geom_smooth(method = "lm")+
  ylab("Duration in Days")+
  xlab("Elevation")

```


```{r, message=F, warning=F, echo = FALSE, fig.align='center'}
#dev.off()
#dev.new()
  MainTitle = paste("Elevation and Duration in Days")
  grid.newpage()
  pushViewport(viewport(layout = grid.layout(3, 2, heights = unit(c(0.1, 1,1), "null"))))
  grid.text(MainTitle, vp = viewport(layout.pos.row = 1, layout.pos.col = 1:2, just = "center"))
  print(a, vp = viewport(layout.pos.row = 2, layout.pos.col = 1),newpage=FALSE)
  print(b, vp = viewport(layout.pos.row = 2, layout.pos.col = 2),newpage=FALSE)
  print(d, vp = viewport(layout.pos.row = 3, layout.pos.col = 1:2),newpage=FALSE)


```

An interesting finding fomr this graph is the outlier that was located at the top for Duration in Days. We can see that there is a flood event that happend in the USA and lasted for 419 days. The next closest was 168 days which occured in Zambia. We can also see a negative correlation with the elevation and duration in days. This was removed in the plotting due to resolution.


```{r, message=F, warning=F, echo = FALSE, fig.align='center'}

filtered = filter(df, elevation > 0)

a = ggplot(filtered, aes(x=elevation, y=Displaced)) +
    geom_point(alpha = .25, aes(group=hem, colour=hem, fill=hem)) +    # Use hollow circles
    geom_smooth(method=lm)+
  ylab("Displaced")+
  xlab("Elevation")+theme(legend.position="none")
b = ggplot(filtered, aes(x=elevation, y=Dead)) +
    geom_point(alpha = .25,aes(group=hem, colour=hem, fill=hem)) +    # Use hollow circles
   geom_smooth(method=lm)+
  ylab("Dead")+
  xlab("Elevation") + theme(legend.position="none")
c = ggplot(filtered, aes(x=elevation, y=Affected.sq.km)) +
    geom_point(alpha = .25,aes(group=hem, colour=hem, fill=hem)) +    # Use hollow circles
   geom_smooth(method=lm)+
  ylab("Affected Square km")+
  xlab("Elevation")+ theme(legend.position="none") 

d = ggplot(filtered, aes(x=elevation, y=Magnitude..M...)) +
    geom_point(alpha = .25,aes(group=hem, colour=hem, fill=hem)) +    # Use hollow circles
   geom_smooth(method=lm)+
  ylab("Magnitude")+
  xlab("Elevation")+  theme(legend.position="none")
  

```

```{r, message=F, warning=F, echo = FALSE, fig.align='center'}
  MainTitle = "Plots of Different Variables vs Elevation"
  grid.newpage()
  pushViewport(viewport(layout = grid.layout(3, 2, heights = unit(c(0.25, 1,1), "null"))))
  grid.text(MainTitle, vp = viewport(layout.pos.row = 1, layout.pos.col = 1:2))
  print(a, vp = viewport(layout.pos.row = 2, layout.pos.col = 1),newpage=FALSE)
  print(b, vp = viewport(layout.pos.row = 2, layout.pos.col = 2),newpage=FALSE)
  print(c, vp = viewport(layout.pos.row = 3, layout.pos.col = 1),newpage=FALSE)
  print(d, vp = viewport(layout.pos.row = 3, layout.pos.col = 2),newpage=FALSE)
```

From these plots we can notice that there is a negative correlation between elevation and the number of displaced people for the flood events. In contract see a positive correlation between elevation and the number of dead. 

For Affected Square km it might seem that there is no correlation but there is a slightly negative correlation between teh Elevation and Affected Square km. the Y-axis is suppressing this but is not a strong enough correlation to be relevant.


```{r, message=F, warning=F, echo = FALSE, fig.align='center', eval = F}
library(wordcloud)
library(dplyr)
library(stringr)
library(tm)
words = df$Notes.and.Comments..may.include.quoted.headlines.from.copyrighted.news.stories..for.internal.research.purposes.only.
words = as.character(words)

splitting = strsplit(words,"\\s+")



splitting2 = unlist(splitting)
splitting_regex = str_replace_all(splitting2, "[^[:alnum:]]", "")
splitting_regex = str_replace_all(splitting_regex, "[0-9 ]+", "")


stopWords <- stopwords("en")

stopwordindex = splitting_regex %in% stopWords
splitting_filter = splitting_regex[!stopwordindex]
count = 1
length_v = vector(length = length(splitting_filter))


count = 1
for(i in (splitting_filter)){
  if(nchar(i)>3){
    length_v[count] = TRUE
  }else{
    length_v[count] = FALSE
  }
  count = count + 1
}



splitting3 = data.frame(splitting_filter[length_v])
splitting3$count = 1

colnames(splitting3) = c("Word","Count")

grop_by.descriptor <- group_by(splitting3,Word)
word_count <- summarise(grop_by.descriptor,count = n())

word_count_filt = filter(word_count, count >100)

set.seed(1)
require(RColorBrewer)

#words  = as.character(word_count$Descriptor)
wordcloud(freq = word_count_filt$count,word =  word_count_filt$Word,rot.per = 0.15,min.freq =20,colors=brewer.pal(8, "Dark2"))
text(x=0.5, y=1.01, "Entire World")

```


```{r, message=F, warning=F, echo = FALSE, fig.align='center', eval = F}
library(wordcloud)
library(dplyr)
library(stringr)
library(tm)

filtered = filter(df, hem == "Northern" )
words = filtered$Notes.and.Comments..may.include.quoted.headlines.from.copyrighted.news.stories..for.internal.research.purposes.only.
words = as.character(words)

splitting = strsplit(words,"\\s+")



splitting2 = unlist(splitting)
splitting_regex = str_replace_all(splitting2, "[^[:alnum:]]", "")
splitting_regex = str_replace_all(splitting_regex, "[0-9 ]+", "")


stopWords <- stopwords("en")

stopwordindex = splitting_regex %in% stopWords
splitting_filter = splitting_regex[!stopwordindex]
count = 1
length_v = vector(length = length(splitting_filter))


count = 1
for(i in (splitting_filter)){
  if(nchar(i)>3){
    length_v[count] = TRUE
  }else{
    length_v[count] = FALSE
  }
  count = count + 1
}



splitting3 = data.frame(splitting_filter[length_v])
splitting3$count = 1

colnames(splitting3) = c("Word","Count")

grop_by.descriptor <- group_by(splitting3,Word)
word_count <- summarise(grop_by.descriptor,count = n())

word_count_filt = filter(word_count, count >100)

set.seed(1)
require(RColorBrewer)

#words  = as.character(word_count$Descriptor)
wordcloud(freq = word_count_filt$count,word =  word_count_filt$Word,rot.per = 0.15,min.freq =20,colors=brewer.pal(8, "Dark2"))

text(x=0.5, y=1.01, "Northern Hemisphere")

```

```{r, message=F, warning=F, echo = FALSE, fig.align='center', eval = F}
library(wordcloud)
library(dplyr)
library(stringr)
library(tm)

filtered = filter(df, hem == "Southern" )
words = filtered$Notes.and.Comments..may.include.quoted.headlines.from.copyrighted.news.stories..for.internal.research.purposes.only.
words = as.character(words)

splitting = strsplit(words,"\\s+")



splitting2 = unlist(splitting)
splitting_regex = str_replace_all(splitting2, "[^[:alnum:]]", "")
splitting_regex = str_replace_all(splitting_regex, "[0-9 ]+", "")


stopWords <- stopwords("en")

stopwordindex = splitting_regex %in% stopWords
splitting_filter = splitting_regex[!stopwordindex]
count = 1
length_v = vector(length = length(splitting_filter))


count = 1
for(i in (splitting_filter)){
  if(nchar(i)>3){
    length_v[count] = TRUE
  }else{
    length_v[count] = FALSE
  }
  count = count + 1
}



splitting3 = data.frame(splitting_filter[length_v])
splitting3$count = 1

colnames(splitting3) = c("Word","Count")

grop_by.descriptor <- group_by(splitting3,Word)
word_count <- summarise(grop_by.descriptor,count = n())

word_count_filt = filter(word_count, count >100)

set.seed(1)
require(RColorBrewer)

#words  = as.character(word_count$Descriptor)
wordcloud(freq = word_count_filt$count,word =  word_count_filt$Word,rot.per = 0.15,min.freq =20,colors=brewer.pal(8, "Dark2"), main = "Title")

text(x=0.5, y=1.01, "Southern Hemisphere")

```


```{r, message=F, warning=F, echo = FALSE, fig.align='center', eval = F}
library(wordcloud)
library(dplyr)
library(stringr)
library(tm)

filtered = filter(df, hem == "Northern" )
words = filtered$Notes.and.Comments..may.include.quoted.headlines.from.copyrighted.news.stories..for.internal.research.purposes.only.
words = as.character(words)

splitting = strsplit(words,"\\s+")



splitting2 = unlist(splitting)
splitting_regex = str_replace_all(splitting2, "[^[:alnum:]]", "")
splitting_regex = str_replace_all(splitting_regex, "[0-9 ]+", "")


stopWords <- stopwords("en")

stopwordindex = splitting_regex %in% stopWords
splitting_filter = splitting_regex[!stopwordindex]
count = 1
length_v = vector(length = length(splitting_filter))


count = 1
for(i in (splitting_filter)){
  if(nchar(i)>3){
    length_v[count] = TRUE
  }else{
    length_v[count] = FALSE
  }
  count = count + 1
}



splitting3 = data.frame(splitting_filter[length_v])
splitting3$count = 1

colnames(splitting3) = c("Word","Count")

grop_by.descriptor <- group_by(splitting3,Word)
word_count <- summarise(grop_by.descriptor,count = n())

word_count_filt = filter(word_count, count >100)

set.seed(1)
require(RColorBrewer)

#words  = as.character(word_count$Descriptor)
wordcloud(freq = word_count_filt$count,word =  word_count_filt$Word,rot.per = 0.15,min.freq =20,colors=brewer.pal(8, "Dark2"), main = "Title")

text(x=0.5, y=1, "Northern Hemisphere")


```


```{r, warnings = FALSE, message=FALSE, echo = FALSE, fig.align='center',eval=FALSE}
library(chron)
library(RColorBrewer)
library(lattice)

library(ncdf4)
library(RNetCDF)
setwd("/Users/bobminnich/Documents/Columbia/Courses/DataVisualization/Homework2/")

ncin <- open.nc("NOAA_Daily_phi_500mb.nc")

print.nc(ncin)
dat<-read.nc(ncin)
z = dat$phi[ , , 2]
ylat<-dat$Y
time = dat$T
xlon<-dat$X
xlon = xlon -180

#Close file


```



```{r, warnings = FALSE, message=FALSE, echo = FALSE, fig.align='center',eval=FALSE}
library(fields)
library(maptools)

data(wrld_simpl)

#Define min/max values to plot and colors for plotting
zmin=0.

zmax=20.

clevs<-c(0,2,4,6,8,10,12,14,16,18,20,50)

ccols<-c("#5D00FF", "#002EFF","#00B9FF","#00FFB9" ,"#00FF2E","#5DFF00","#E8FF00", "#FF8B00","red", "#FF008B","#E800FF")

palette(ccols)

#Plot image  (see result in Figure 3)

dev.off()
dev.new()
z = dat$phi[ , , 1]
ylat =ylat[order(ylat)]
image.plot(xlon,ylat,z,col=palette(ccols))
plot(wrld_simpl,add=TRUE)

start_date <- as.Date("1-Apr-2002", "%d-%b-%Y")

nextdate = start_date
for(i in c(1:1000)){
  test = filter(df, nextdate > Began & nextdate < Ended & Centroid.Y>=35)
  print(dim(test))
  print(nextdate)
  if(length(dim(test)[1]) > 0){
    a = test
    date_a = nextdate
    break
  }else{
  }
  nextdate = nextdate + 1
}

library(stats)
 
```



```{r, warnings = FALSE, message=FALSE, echo = FALSE, fig.align='center',eval=FALSE}
coords = xy.coords(xlon, ylat, recycle=TRUE)

ratio = length(xlon)/length(ylat)
y = spline(ylat,n = length(ylat)*8)$y
x = spline(xlon,n = length(y)*ratio)$y


```

```{r, warnings = FALSE, message=FALSE, echo = FALSE, fig.align='center',eval=FALSE}
width = 100
heigth = 5
windows.options(width=width, height=height)
mar <- par("mar"); mar[c(2, 4)] <- 0

setwd("/Users/bobminnich/Documents/Columbia/Courses/DataVisualization/photos")
zmax = max(z)
zmin = min(z)
time = dat$T

#1948-01-01
start_date_phi <- as.Date("1948-01-01", "%Y-%m-%d")
start_date_floods <- as.Date("1985-01-01", "%Y-%m-%d")
start_date_plots  <- as.Date("2003-01-01", "%Y-%m-%d")

start_date_plots2  <- as.Date("2005-03-02", "%Y-%m-%d")

offset = as.numeric(start_date_floods - start_date_phi)
offset2 = as.numeric(start_date_plots - start_date_phi)
time2 = time[offset2:length(time)]
time3 = time2[1:2]
start_date = start_date_phi + offset2-1

#Begining date of FLOODS 1985-01-01
plotdf = filter(df,Centroid.Y>=35)
count = 1
for(i in seq(min(time3),max(time3),1) ){
  nextdate = (start_date + count)
  print(nextdate)
  name = paste("world",i,".png",sep='')
  png(name,width=600,height=350)
  z2 = dat$phi[ , , i]

      mydf = data.frame()
      for(i in c(1:length(z2[,1]))){
        ys = spline(z2[i,],n = length(y))$y
        mydf = rbind(mydf, ys)
      }
      nmydf = data.frame()
      for(i in c(1:length(mydf[1,]))){
        ys = spline(mydf[,i],n = length(x))$y
        nmydf = rbind(nmydf, ys)
      }
      z_test = t(as.matrix(nmydf))
      #z_test = (as.matrix(nmydf))

      y_ord =y[order(y)]

  zmax = max(z)
  zmin = min(z)
      image.plot(x,y_ord,z_test,col= rainbow(200)) #col=palette(ccols))
      plot(wrld_simpl,add=TRUE)
  main_title = paste("This is a plot of ", (format(nextdate, format="%B %d %Y")))
  
  test = filter(plotdf, nextdate >= Began & nextdate <= Ended)
  if(length(dim(test)[1]) > 0){
    a = test
    date_a = nextdate
    points(x = a$Centroid.X, y = a$Centroid.Y,cex = 3, pch= 19)
  }else{
  }
  mtext(main_title,side = 3)
  dev.off()
  count = count + 1
}


make.mov <- function(){
     system("convert *.png -set delay 1/2  2003-OCT.gif")
     #1/1 is 1 second per 2 frames
}

make.mov()



```

Several additional wordclouds were created to investigate the different components of flooding events. The first wordcloud shows the 100 countries with the greatest number of events since 1985. The USA and China seem to be the two countries that were most affected, with the Philippines, Indonesia and India close behind. The second wordcloud highlights the attributes of the "detailed locations" column in the dataset and gives interesting insight into the types of areas that are commonly affected by flooding. The third wordcloud attempts to examine the types of events that cause flooding. Clearly, heavy and torrential rains are what usually cause floods.

```{r, echo=FALSE}
create_wc <- function(col_num){
  countries <- df[,col_num]
  countries <- tolower(countries)
  countries <- removePunctuation(countries)
  countries <- removeNumbers(countries)
  countries <- removeWords(countries,stopwords("english"))
  
  myCorpus <- Corpus(VectorSource(countries))
  myTDM <- TermDocumentMatrix(myCorpus)
  findFreqTerms(myTDM)
  
  m <- as.matrix(myTDM)
  v <- sort(rowSums(m),decreasing=TRUE)
  d <- data.frame(word = names(v),freq=v)
  
  pal <- brewer.pal(8,"Dark2")
  wordcloud(d$word,d$freq,max.words=100,colors = pal,random.order=FALSE,rot.per=0.30,fixed.asp = TRUE)
}

create_wc(4)
create_wc(8)
create_wc(16)
```

By looking at 2003 more closely, we can plot the number of deaths and displacements by month in that year. Both plots showed a similar overall trend; the number of deaths and displacements both reached their maximums from June to August. The faded turquoise line maps the actual number of deaths and displacements, while the dark blue smooth curve is an attempt to represent the overall trend in a more visually appealing way.

```{r, echo=FALSE}
newdf = df[which((df$Began>="2003-01-01")&(df$Began<="2003-12-31")),]

# can just remove country in dplyr and ggplots below to revert back to original.
#### Deaths vs. Month

year03 <- newdf %>%
  mutate(Month = format(Began, "%m"), Year = format(Began, "%Y"),Date = format(Began, "%m-%Y")) %>%
  group_by(Month, Year, Date) %>%
  summarise(Dead = sum(Dead))
year03<-as.data.frame(year03)
year03$Month<-as.numeric(year03$Month)

#year03<- filter(year03, Country=="USA"|Country=="China"|Country=="Philippines"|Country=="Indonesia"|Country=="India")

c <-ggplot(year03, aes(x=year03$Month,y=year03$Dead,group=1)) +
  geom_point(size=1.5,colour="#7fcdbb") + 
  geom_line(size=1.2,colour="#7fcdbb") +
  stat_smooth(method="lm", formula= y~poly(x,8),se=F,n=80,size=2,color="#253494") +
  scale_x_continuous(breaks=c(1:12),labels=year03$Date) +
  labs(x="Month-Year",y="Number of Flood Deaths",title="Flood Deaths vs. Time of Year") +
  theme(axis.text=element_text(size=8),axis.title=element_text(size=16),plot.title=element_text(size=18,face="bold"))
c

# Displacements vs. Month

year03 <- newdf %>%
  mutate(Month = format(Began, "%m"), Year = format(Began, "%Y"),Date = format(Began, "%m-%Y")) %>%
  group_by(Month, Year, Date) %>%
  summarise(Displaced = sum(Displaced))
year03<-as.data.frame(year03)
year03$Month<-as.numeric(year03$Month)

c <-ggplot(year03, aes(x=year03$Month,y=year03$Displaced,group=1)) +
  geom_point(size=1.5,colour="#7fcdbb") + 
  geom_line(size=1.2,colour="#7fcdbb") +
  stat_smooth(method="lm", formula= y~poly(x,8),se=F,n=80,size=2,color="#253494") +
  scale_x_continuous(breaks=c(1:12),labels=year03$Date) +
  labs(x="Month-Year",y="Number of Flood Displacements",title="Flood Displacements vs. Time of Year") +
  theme(axis.text=element_text(size=8),axis.title=element_text(size=16),plot.title=element_text(size=18,face="bold"))
c
```

Displayed below is an interactive world map showing the number of deaths by country in 2003. The countries with fewer deaths are lighter and the countries with more deaths are darker. Run the mouse over a country to display its name and number of deaths associated with it.

```{r, echo=FALSE,results='asis',tidy=TRUE}
# Google vis chart of Deaths in 2003

op <- options(gvis.plot.tag='chart')
year03 <- newdf %>% group_by(Country) %>% summarise(Dead = sum(Dead))
year03<-as.data.frame(year03)

Geo = gvisGeoChart(year03, locationvar="Country", colorvar="Dead", 
                   options=list(projection="kavrayskiy-vii",
                                colorAxis= "{colors: ['#FED976','#FEB24C','#FD8D3C','#FC4E2A','#E31A1C','#B10026']}",
                                backgroundColor="#deebf7",
                                datalessRegionColor="#f0f0f0",
                                height=500,
                                width=900))
plot(Geo)
```

Next is another interactive World map showing the number of displaced individuals in 2003. It has the same format and style as the previous one; run the mouse over the countries to see the country name and magnitude.

```{r,echo=FALSE,results='asis',tidy=TRUE}
#Google vis charts of Displacements in 2003

year03 <- newdf %>% group_by(Country) %>% summarise(Displaced = sum(Displaced))
year03<-as.data.frame(year03)

Geo2 = gvisGeoChart(year03, locationvar="Country", colorvar="Displaced", 
                   options=list(projection="kavrayskiy-vii",
                                colorAxis= "{colors: ['#FED976','#FEB24C','#FD8D3C','#FC4E2A','#E31A1C','#B10026']}",
                                backgroundColor="#deebf7",
                                datalessRegionColor="#f0f0f0",
                                height=500,
                                width=900))
plot(Geo2)
```

Lastly, an interactive google map with tagged flood locations (1985-present) is displayed below. This feature allows the user to zoom in and see exactly where a flood event occured. Clicking the tag shows the date of the event.

```{r, echo=FALSE, results='asis', tidy=TRUE}
df$latlong <- paste(df$latitude,df$longitude,sep=":")

locmap <- gvisMap(df, locationvar="latlong", tipvar = "Began",
                     options=list(showTip=TRUE, 
                                  showLine=TRUE, 
                                  enableScrollWheel=TRUE,
                                  mapType='hybrid',
                                  useMapTypeControl=TRUE,
                                  zoomLevel=3,
                                  width=800,
                                  height=700))
plot(locmap)
```

After some general analysis we noticed that the most floods took place in 2003. Of the floods that occurred in 2003, the USA had recorded the most floods. So we decided to look a little further into floods in the USA in 2003. Below is a plot of floods by month in the USA in 2003.   

```{r, message=F, warning=F, echo = F}
library(xlsx)

a <- df[-which(df$Began == "" | df$Began == "#N/A"), ]
a$Began = as.character(a$Began)
elems <- unlist( strsplit(a$Began , "-", fixed = TRUE ) )
m <- matrix( elems , ncol = 3 , byrow = TRUE )
colnames(m) <- c('day', 'month', 'year')
by_year <- cbind(a, m)

by_year$year = as.numeric(levels(by_year$year))[as.integer(by_year$year)]
dat03 <- subset(by_year, year == 03, 
                select=c(Register..:year))

dat03$month=as.character(dat03$month)
dat03$month[dat03$month=='Jan'] <- 1
dat03$month[dat03$month=='Feb'] <- 2
dat03$month[dat03$month=='Mar'] <- 3
dat03$month[dat03$month=='Apr'] <- 4
dat03$month[dat03$month=='May'] <- 5
dat03$month[dat03$month=='Jun'] <- 6
dat03$month[dat03$month=='Jul'] <- 7
dat03$month[dat03$month=='Aug'] <- 8
dat03$month[dat03$month=='Sep'] <- 9
dat03$month[dat03$month=='Oct'] <- 10
dat03$month[dat03$month=='Nov'] <- 11
dat03$month[dat03$month=='Dec'] <- 12

USA03 <- subset(dat03, Country == "USA", 
              select=c(Register..:year))

qplot(month, data=USA03, geom="bar", fill=month) +
        #labs(title = "Floods by Month in USA, 2003") +
        scale_x_discrete(limits=c(1,2,3,4,5,6,7,8,9,10,11,12)) +
        labs(x="Month") + 
        labs(y="Total") +
        theme_classic() +
        theme(legend.position="none")
```

You can see that the most amount of floods began in February, and there was at least one flood in every month of 2003 in the USA. Now we'll look into the data describing the damage caused by the floods by month in the USA.  

# Damage by Month in USA, 2003

```{r, message=F, warning=F, echo = F}

library(Rmisc)

displaced03 <- USA03[c(12, 13, 14, 18, 38)]
displaced03$Duration.in.Days = as.numeric(levels(displaced03$Duration.in.Days))[as.integer(displaced03$Duration.in.Days)]
displaced03$Dead = as.numeric(levels(displaced03$Dead))[as.integer(displaced03$Dead)]
displaced03$Displaced = as.numeric(levels(displaced03$Displaced))[as.integer(displaced03$Displaced)]
displaced03$Affected.sq.km = as.numeric(levels(displaced03$Affected.sq.km))[as.integer(displaced03$Affected.sq.km)]

displaced <- ggplot(displaced03, aes(month, Displaced, fill=month)) +
        geom_bar(stat="identity") +
        scale_x_discrete(limits=c(1,2,3,4,5,6,7,8,9,10,11,12)) +
        labs(title = "Total Displaced") +
        labs(x = "Month") +
        theme_classic() +
        theme(legend.position="none") 

dead <- ggplot(displaced03, aes(month, Dead, fill=month)) +
        geom_bar(stat="identity") +
        scale_x_discrete(limits=c(1,2,3,4,5,6,7,8,9,10,11,12)) +
        labs(title = "Total Dead") +
        labs(x = "Month") +
        theme_classic() +
        theme(legend.position="none") 

duration <- ggplot(displaced03, aes(month, Duration.in.Days, fill=month)) +
        geom_bar(stat="identity") +
        scale_x_discrete(limits=c(1,2,3,4,5,6,7,8,9,10,11,12)) +
        labs(title = "Total Days of Flooding") +
        labs(x = "Month") +
        labs(y = "Duration") +
        theme_classic() +
        theme(legend.position="none") 

area <- ggplot(displaced03, aes(month, Affected.sq.km, fill=month)) +
        geom_bar(stat="identity") +
        scale_x_discrete(limits=c(1,2,3,4,5,6,7,8,9,10,11,12)) +
        labs(title = "Total Affected Area") +
        labs(x = "Month") +
        labs(y = "Sq. Kilometers") +
        theme_classic() +
        theme(legend.position="none") 

multiplot(displaced, dead, duration, area, cols=2)
```

As mentioned before, February was the month that had the most recorded floods (5). It isnât surprising that February also had the largest total of days of flooding, which reached around forty, and also had the largest total affected area, by a significant margin. Considering these facts, it is surprising that the total number of displaced peoples in February is very low, especially compared to the total displaced peoples in May, June, July, and September. Also, the total number of dead is low relative to other months that had fewer floods that affected a smaller total area. 

One might assume that this is because the magnitude of those floods was less, but in fact, all but one of the floods that occurred in February were above 5.064516, which was the average flood magnitude in the USA in 2003. Another explanation for this is where the floods occurred. The February floods were in southern California, eastern Kentucky, the southern Mid-Atlantic, and along the Gulf Coast (Mississippi and Louisiana), and in southwestern Virginia and West Virginia. The only area that any people were recorded displaced in those floods was in Eastern Kentucky, which is also where two people were recorded dead. I would imagine that the only way to explain this phenomenon is that these locations are less populated than the locations of some of the other floods in the USA in 2003. It is also possible that these locations were more prepared for the floods and therefore less problems and casualties were incurred. Unfortunately, there was no data recorded for the damage in US dollars for these floods. 


# Pressure Levels Between Floods

We decided it might be interesting to find a location where flooding occurred more than once within a few months, and look at the pressure level day-by-day to see if there was any pattern.  We looked at floods that began on September 18, 2003 and November 19, 2003, and ended on September 24, 2003 and November 22, 2003, respectively. The main cause of the September flood was a tropical cyclone and heavy rain was the main cause of the November hurricane. The magnitudes and locations of the floods were 6.1, 6.2 and (-78.4245, 37.3311), (-79.3157, 38.8759), respectively. These coordinates correspond to a point in the mid-Atlantic, and specifically, parts of Maryland, West Virginia, and Virginia experienced flooding during both of these events.   

```{r, message=F, warning=F, echo = F}

setwd("/Users/johnsibilla/desktop/EDAV Project 2")
ncin <- open.nc("NOAA_Daily_phi_500mb.nc")

print.nc(ncin)
dat<-read.nc(ncin)
z = dat$phi[ , , 2]
ylat<-dat$Y
time = dat$T
xlon<-dat$X
xlon = xlon -180
press<-dat$P

start_date_phi <- as.Date("1948-01-01", "%Y-%m-%d")

#pulling pressure data for dates between floods (9/8/03-11/25/03)
start_date_plots_14 <- as.Date("2003-09-08", "%Y-%m-%d")
start_date_plots_13 <- as.Date("2003-09-09", "%Y-%m-%d")
start_date_plots_12 <- as.Date("2003-09-10", "%Y-%m-%d")
start_date_plots_11 <- as.Date("2003-09-11", "%Y-%m-%d")
start_date_plots_10 <- as.Date("2003-09-12", "%Y-%m-%d")
start_date_plots09 <- as.Date("2003-09-13", "%Y-%m-%d")
start_date_plots08 <- as.Date("2003-09-14", "%Y-%m-%d")
start_date_plots07 <- as.Date("2003-09-15", "%Y-%m-%d")
start_date_plots06 <- as.Date("2003-09-16", "%Y-%m-%d")
start_date_plots05 <- as.Date("2003-09-17", "%Y-%m-%d")
start_date_plots04 <- as.Date("2003-09-18", "%Y-%m-%d")
start_date_plots03 <- as.Date("2003-09-19", "%Y-%m-%d")
start_date_plots02 <- as.Date("2003-09-20", "%Y-%m-%d")
start_date_plots01 <- as.Date("2003-09-21", "%Y-%m-%d")
start_date_plots0 <- as.Date("2003-09-22", "%Y-%m-%d")
start_date_plots1  <- as.Date("2003-09-23", "%Y-%m-%d")
start_date_plots2  <- as.Date("2003-09-24", "%Y-%m-%d")
start_date_plots3  <- as.Date("2003-09-25", "%Y-%m-%d")
start_date_plots4  <- as.Date("2003-09-26", "%Y-%m-%d")
start_date_plots5  <- as.Date("2003-09-27", "%Y-%m-%d")
start_date_plots6  <- as.Date("2003-09-28", "%Y-%m-%d")
start_date_plots7  <- as.Date("2003-09-29", "%Y-%m-%d")
start_date_plots8  <- as.Date("2003-09-30", "%Y-%m-%d")
start_date_plots9  <- as.Date("2003-10-1", "%Y-%m-%d")
start_date_plots10 <- as.Date("2003-10-2", "%Y-%m-%d")
start_date_plots11 <- as.Date("2003-10-3", "%Y-%m-%d")
start_date_plots12 <- as.Date("2003-10-4", "%Y-%m-%d")
start_date_plots13 <- as.Date("2003-10-5", "%Y-%m-%d")
start_date_plots14 <- as.Date("2003-10-6", "%Y-%m-%d")
start_date_plots15 <- as.Date("2003-10-7", "%Y-%m-%d")
start_date_plots16 <- as.Date("2003-10-8", "%Y-%m-%d")
start_date_plots17 <- as.Date("2003-10-9", "%Y-%m-%d")
start_date_plots18 <- as.Date("2003-10-10", "%Y-%m-%d")
start_date_plots19 <- as.Date("2003-10-11", "%Y-%m-%d")
start_date_plots20 <- as.Date("2003-10-12", "%Y-%m-%d")
start_date_plots21 <- as.Date("2003-10-13", "%Y-%m-%d")
start_date_plots22 <- as.Date("2003-10-14", "%Y-%m-%d")
start_date_plots23 <- as.Date("2003-10-15", "%Y-%m-%d")
start_date_plots24 <- as.Date("2003-10-16", "%Y-%m-%d")
start_date_plots25 <- as.Date("2003-10-17", "%Y-%m-%d")
start_date_plots26 <- as.Date("2003-10-18", "%Y-%m-%d")
start_date_plots27 <- as.Date("2003-10-19", "%Y-%m-%d")
start_date_plots28 <- as.Date("2003-10-20", "%Y-%m-%d")
start_date_plots29 <- as.Date("2003-10-21", "%Y-%m-%d")
start_date_plots30 <- as.Date("2003-10-22", "%Y-%m-%d")
start_date_plots31 <- as.Date("2003-10-23", "%Y-%m-%d")
start_date_plots32 <- as.Date("2003-10-24", "%Y-%m-%d")
start_date_plots33 <- as.Date("2003-10-25", "%Y-%m-%d")
start_date_plots34 <- as.Date("2003-10-26", "%Y-%m-%d")
start_date_plots35 <- as.Date("2003-10-27", "%Y-%m-%d")
start_date_plots36 <- as.Date("2003-10-28", "%Y-%m-%d")
start_date_plots37 <- as.Date("2003-10-29", "%Y-%m-%d")
start_date_plots38 <- as.Date("2003-10-30", "%Y-%m-%d")
start_date_plots39 <- as.Date("2003-10-31", "%Y-%m-%d")
start_date_plots40 <- as.Date("2003-11-01", "%Y-%m-%d")
start_date_plots41 <- as.Date("2003-11-02", "%Y-%m-%d")
start_date_plots42 <- as.Date("2003-11-03", "%Y-%m-%d")
start_date_plots43 <- as.Date("2003-11-04", "%Y-%m-%d")
start_date_plots44 <- as.Date("2003-11-05", "%Y-%m-%d")
start_date_plots45 <- as.Date("2003-11-06", "%Y-%m-%d")
start_date_plots46 <- as.Date("2003-11-07", "%Y-%m-%d")
start_date_plots47 <- as.Date("2003-11-08", "%Y-%m-%d")
start_date_plots48 <- as.Date("2003-11-09", "%Y-%m-%d")
start_date_plots49 <- as.Date("2003-11-10", "%Y-%m-%d")
start_date_plots50 <- as.Date("2003-11-11", "%Y-%m-%d")
start_date_plots51 <- as.Date("2003-11-12", "%Y-%m-%d")
start_date_plots52 <- as.Date("2003-11-13", "%Y-%m-%d")
start_date_plots53 <- as.Date("2003-11-14", "%Y-%m-%d")
start_date_plots54 <- as.Date("2003-11-15", "%Y-%m-%d")
start_date_plots55 <- as.Date("2003-11-16", "%Y-%m-%d")
start_date_plots56 <- as.Date("2003-11-17", "%Y-%m-%d")
start_date_plots57 <- as.Date("2003-11-18", "%Y-%m-%d")
start_date_plots58 <- as.Date("2003-11-19", "%Y-%m-%d")
start_date_plots59 <- as.Date("2003-11-20", "%Y-%m-%d")
start_date_plots60 <- as.Date("2003-11-21", "%Y-%m-%d")
start_date_plots61 <- as.Date("2003-11-22", "%Y-%m-%d")
start_date_plots62 <- as.Date("2003-11-23", "%Y-%m-%d")
start_date_plots63 <- as.Date("2003-11-24", "%Y-%m-%d")
start_date_plots64 <- as.Date("2003-11-25", "%Y-%m-%d")


offset_14 = as.numeric(start_date_plots_14 - start_date_phi)
offset_13 = as.numeric(start_date_plots_13 - start_date_phi)
offset_12 = as.numeric(start_date_plots_12 - start_date_phi)
offset_11 = as.numeric(start_date_plots_11 - start_date_phi)
offset_10 = as.numeric(start_date_plots_10 - start_date_phi)
offset09 = as.numeric(start_date_plots09 - start_date_phi)
offset08 = as.numeric(start_date_plots08 - start_date_phi)
offset07 = as.numeric(start_date_plots07 - start_date_phi)
offset06 = as.numeric(start_date_plots06 - start_date_phi)
offset05 = as.numeric(start_date_plots05 - start_date_phi)
offset04 = as.numeric(start_date_plots04 - start_date_phi)
offset03 = as.numeric(start_date_plots03 - start_date_phi)
offset02 = as.numeric(start_date_plots02 - start_date_phi)
offset01 = as.numeric(start_date_plots01 - start_date_phi)
offset0 = as.numeric(start_date_plots0 - start_date_phi)
offset1 = as.numeric(start_date_plots1 - start_date_phi)
offset2 = as.numeric(start_date_plots2 - start_date_phi)
offset3 = as.numeric(start_date_plots3 - start_date_phi)
offset4 = as.numeric(start_date_plots4 - start_date_phi)
offset5 = as.numeric(start_date_plots5 - start_date_phi)
offset6 = as.numeric(start_date_plots6 - start_date_phi)
offset7 = as.numeric(start_date_plots7 - start_date_phi)
offset8 = as.numeric(start_date_plots8 - start_date_phi)
offset9 = as.numeric(start_date_plots9 - start_date_phi)
offset10 = as.numeric(start_date_plots10 - start_date_phi)
offset11 = as.numeric(start_date_plots11 - start_date_phi)
offset12 = as.numeric(start_date_plots12 - start_date_phi)
offset13 = as.numeric(start_date_plots13 - start_date_phi)
offset14 = as.numeric(start_date_plots14 - start_date_phi)
offset15 = as.numeric(start_date_plots15 - start_date_phi)
offset16 = as.numeric(start_date_plots16 - start_date_phi)
offset17 = as.numeric(start_date_plots17 - start_date_phi)
offset18 = as.numeric(start_date_plots18 - start_date_phi)
offset19 = as.numeric(start_date_plots19 - start_date_phi)
offset20 = as.numeric(start_date_plots20 - start_date_phi)
offset21 = as.numeric(start_date_plots21 - start_date_phi)
offset22 = as.numeric(start_date_plots22 - start_date_phi)
offset23 = as.numeric(start_date_plots23 - start_date_phi)
offset24 = as.numeric(start_date_plots24 - start_date_phi)
offset25 = as.numeric(start_date_plots25 - start_date_phi)
offset26 = as.numeric(start_date_plots26 - start_date_phi)
offset27 = as.numeric(start_date_plots27 - start_date_phi)
offset28 = as.numeric(start_date_plots28 - start_date_phi)
offset29 = as.numeric(start_date_plots29 - start_date_phi)
offset30 = as.numeric(start_date_plots30 - start_date_phi)
offset31 = as.numeric(start_date_plots31 - start_date_phi)
offset32 = as.numeric(start_date_plots32 - start_date_phi)
offset33 = as.numeric(start_date_plots33 - start_date_phi)
offset34 = as.numeric(start_date_plots34 - start_date_phi)
offset35 = as.numeric(start_date_plots35 - start_date_phi)
offset36 = as.numeric(start_date_plots36 - start_date_phi)
offset37 = as.numeric(start_date_plots37 - start_date_phi)
offset38 = as.numeric(start_date_plots38 - start_date_phi)
offset39 = as.numeric(start_date_plots39 - start_date_phi)
offset40 = as.numeric(start_date_plots40 - start_date_phi)
offset41 = as.numeric(start_date_plots41 - start_date_phi)
offset42 = as.numeric(start_date_plots42 - start_date_phi)
offset43 = as.numeric(start_date_plots43 - start_date_phi)
offset44 = as.numeric(start_date_plots44 - start_date_phi)
offset45 = as.numeric(start_date_plots45 - start_date_phi)
offset46 = as.numeric(start_date_plots46 - start_date_phi)
offset47 = as.numeric(start_date_plots47 - start_date_phi)
offset48 = as.numeric(start_date_plots48 - start_date_phi)
offset49 = as.numeric(start_date_plots49 - start_date_phi)
offset50 = as.numeric(start_date_plots50 - start_date_phi)
offset51 = as.numeric(start_date_plots51 - start_date_phi)
offset52 = as.numeric(start_date_plots52 - start_date_phi)
offset53 = as.numeric(start_date_plots53 - start_date_phi)
offset54 = as.numeric(start_date_plots54 - start_date_phi)
offset55 = as.numeric(start_date_plots55 - start_date_phi)
offset56 = as.numeric(start_date_plots56 - start_date_phi)
offset57 = as.numeric(start_date_plots57 - start_date_phi)
offset58 = as.numeric(start_date_plots58 - start_date_phi)
offset59 = as.numeric(start_date_plots59 - start_date_phi)
offset60 = as.numeric(start_date_plots60 - start_date_phi)
offset61 = as.numeric(start_date_plots61 - start_date_phi)
offset62 = as.numeric(start_date_plots62 - start_date_phi)
offset63 = as.numeric(start_date_plots63 - start_date_phi)
offset64 = as.numeric(start_date_plots64 - start_date_phi)


z_14 = dat$phi[ , , offset_14]
z_13 = dat$phi[ , , offset_13]
z_12 = dat$phi[ , , offset_12]
z_11 = dat$phi[ , , offset_11]
z_10 = dat$phi[ , , offset_10]
z09 = dat$phi[ , , offset09]
z08 = dat$phi[ , , offset08]
z07 = dat$phi[ , , offset07]
z06 = dat$phi[ , , offset06]
z05 = dat$phi[ , , offset05]
z04 = dat$phi[ , , offset04]
z03 = dat$phi[ , , offset03]
z02 = dat$phi[ , , offset02]
z01 = dat$phi[ , , offset01]
z0 = dat$phi[ , , offset0]
z1 = dat$phi[ , , offset1]
z2 = dat$phi[ , , offset2]
z3 = dat$phi[ , , offset3]
z4 = dat$phi[ , , offset4]
z5 = dat$phi[ , , offset5]
z6 = dat$phi[ , , offset6]
z7 = dat$phi[ , , offset7]
z8 = dat$phi[ , , offset8]
z9 = dat$phi[ , , offset9]
z10 = dat$phi[ , , offset10]
z11 = dat$phi[ , , offset11]
z12 = dat$phi[ , , offset12]
z13 = dat$phi[ , , offset13]
z14 = dat$phi[ , , offset14]
z15 = dat$phi[ , , offset15]
z16 = dat$phi[ , , offset16]
z17 = dat$phi[ , , offset17]
z18 = dat$phi[ , , offset18]
z19 = dat$phi[ , , offset19]
z20 = dat$phi[ , , offset20]
z21 = dat$phi[ , , offset21]
z22 = dat$phi[ , , offset22]
z23 = dat$phi[ , , offset23]
z24 = dat$phi[ , , offset24]
z25 = dat$phi[ , , offset25]
z26 = dat$phi[ , , offset26]
z27 = dat$phi[ , , offset27]
z28 = dat$phi[ , , offset28]
z29 = dat$phi[ , , offset29]
z30 = dat$phi[ , , offset30]
z31 = dat$phi[ , , offset31]
z32 = dat$phi[ , , offset32]
z33 = dat$phi[ , , offset33]
z34 = dat$phi[ , , offset34]
z35 = dat$phi[ , , offset35]
z36 = dat$phi[ , , offset36]
z37 = dat$phi[ , , offset37]
z38 = dat$phi[ , , offset38]
z39 = dat$phi[ , , offset39]
z40 = dat$phi[ , , offset40]
z41 = dat$phi[ , , offset41]
z42 = dat$phi[ , , offset42]
z43 = dat$phi[ , , offset43]
z44 = dat$phi[ , , offset44]
z45 = dat$phi[ , , offset45]
z46 = dat$phi[ , , offset46]
z47 = dat$phi[ , , offset47]
z48 = dat$phi[ , , offset48]
z49 = dat$phi[ , , offset49]
z50 = dat$phi[ , , offset50]
z51 = dat$phi[ , , offset51]
z52 = dat$phi[ , , offset52]
z53 = dat$phi[ , , offset53]
z54 = dat$phi[ , , offset54]
z55 = dat$phi[ , , offset55]
z56 = dat$phi[ , , offset56]
z57 = dat$phi[ , , offset57]
z58 = dat$phi[ , , offset58]
z59 = dat$phi[ , , offset59]
z60 = dat$phi[ , , offset60]
z61 = dat$phi[ , , offset61]
z62 = dat$phi[ , , offset62]
z63 = dat$phi[ , , offset63]
z64 = dat$phi[ , , offset64]

d <- data.frame()

d <- rbind(z_14[,14][41],
           z_13[,14][41],
           z_12[,14][41],
           z_11[,14][41],
           z_10[,14][41],
           z09[,14][41],
           z08[,14][41],
           z07[,14][41],
           z06[,14][41],
           z05[,14][41],
           z04[,14][41],
           z03[,14][41],
           z02[,14][41],
           z01[,14][41],
           z0[,14][41],
           z1[,14][41],
           z2[,14][41],
           z3[,14][41],
           z4[,14][41],
           z5[,14][41],
           z6[,14][41],
           z7[,14][41],
           z8[,14][41],
           z9[,14][41],
           z10[,14][41],
           z11[,14][41],
           z12[,14][41],
           z13[,14][41],
           z14[,14][41],
           z15[,14][41],
           z16[,14][41],
           z17[,14][41],
           z18[,14][41],
           z19[,14][41],
           z20[,14][41],
           z21[,14][41],
           z22[,14][41],
           z23[,14][41],
           z24[,14][41],
           z25[,14][41],
           z26[,14][41],
           z27[,14][41],
           z28[,14][41],
           z29[,14][41],
           z30[,14][41],
           z31[,14][41],
           z32[,14][41],
           z33[,14][41],
           z34[,14][41],
           z35[,14][41],
           z36[,14][41],
           z37[,14][41],
           z38[,14][41],
           z39[,14][41],
           z40[,14][41],
           z41[,14][41],
           z42[,14][41],
           z43[,14][41],
           z44[,14][41],
           z45[,14][41],
           z46[,14][41],
           z47[,14][41],
           z48[,14][41],
           z49[,14][41],
           z50[,14][41],
           z51[,14][41],
           z52[,14][41],
           z53[,14][41],
           z54[,14][41],
           z55[,14][41],
           z56[,14][41],
           z57[,14][41],
           z58[,14][41],
           z59[,14][41],
           z60[,14][41],
           z61[,14][41],
           z62[,14][41],
           z63[,14][41],
           z64[,14][41])

da <- as.data.frame(x=d)
f <- seq(as.Date("2003/9/08"), as.Date("2003/11/25"), "day")
dab <- cbind(da, f)
colnames(dab) <- c("Pressure","Date")

ggplot(dab, aes(Date, Pressure)) + 
        geom_point() +
        geom_line() +
        geom_vline(xintercept = 12313, colour="blue") +
        #geom_vline(xintercept = 12319, colour="blue") +
        geom_vline(xintercept = 12375, colour="blue") +
        #geom_vline(xintercept = 12378, colour="blue") +
        labs(title="Pressure Level Between Floods in USA") +
        labs(x="2003") +
        theme_classic() +
        geom_text(data=subset(dab, Date ==  "2003-09-18" | Date ==  "2003-11-19"),
                  aes(label=Date), colour = "red")
```


The first thing you might notice in the graph is that the pressure level seems to be trending downward over the two-month period starting in September and ending in November. I think one possible explanation for this is the change in seasons. Looking specifically at the pressure level in the days leading up to the beginning of the flood, youâll notice that there was a sharp change in the pressure level. In September, starting on the 15th, the pressure level drops sharply and then increases sharply. In November, starting on the 16th, you can see that the pressure level drops sharply in the days leading up to the beginning of the flood. 

At first glance, these findings might seem interesting, but when you look at the pressure level day-by-day in the days between the two floods, you see that there are many sharp increases and decreases in the pressure level. Since there are know other recorded floods in this region during this time frame I donât think you can completely attribute the flooding and storms in September in November to the change in pressure level in the days leading up to the events. If anything, the pressure level is one factor that contributed to the rain and then flooding in these regions. 
